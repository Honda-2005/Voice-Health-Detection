"""
Voice Health Detection - HIGH ACCURACY Training Pipeline
Optimized with XGBoost, SMOTE, and Ensemble Learning
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, RandomizedSearchCV
from sklearn.ensemble import RandomForestClassifier, VotingClassifier
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    confusion_matrix, classification_report, roc_auc_score
)
from imblearn.over_sampling import SMOTE
from imblearn.pipeline import Pipeline
from xgboost import XGBClassifier
import joblib
import os
import json
from datetime import datetime
import warnings

# Suppress warnings for cleaner output
warnings.filterwarnings('ignore')

# Paths
MODEL_DIR = './ml-service/models'
DATASET_PATH = './ml-service/data/parkinsons.data'

# Create models directory
os.makedirs(MODEL_DIR, exist_ok=True)

print("="*70)
print("ðŸš€ HIGH-PERFORMANCE PARKINSON'S DETECTION MODEL TRAINING")
print("="*70)
print("Techniques: XGBoost + Random Forest Ensemble, SMOTE, Hyperparameter Tuning")
print("Goal: Maximize Accuracy and Sensitivity\n")

# ============================================================================
# STEP 1: DATA LOADING & PREPROCESSING
# ============================================================================

def load_and_preprocess_data():
    """
    Load data and handle class imbalance
    """
    print("\nðŸ“‚ Loading Dataset...")
    
    if not os.path.exists(DATASET_PATH):
        print(f"âŒ Dataset not found: {DATASET_PATH}")
        print("ðŸ“¥ Please download 'parkinsons.data' from UCI Repository")
        return None, None, None
    
    df = pd.read_csv(DATASET_PATH)
    
    # Separate features and target
    X = df.drop(['name', 'status'], axis=1)
    y = df['status']
    
    print(f"âœ… Loaded {len(df)} samples with {X.shape[1]} features")
    
    # Check Class Imbalance
    healthy_count = sum(y == 0)
    parkinsons_count = sum(y == 1)
    print(f"\nðŸ“Š Class Distribution (Before Balancing):")
    print(f"   Healthy (0): {healthy_count} ({healthy_count/len(y)*100:.1f}%)")
    print(f"   Parkinson's (1): {parkinsons_count} ({parkinsons_count/len(y)*100:.1f}%)")
    
    return X, y, df

# ============================================================================
# STEP 2: ADVANCED TRAINING PIPELINE
# ============================================================================

def train_ensemble_model(X, y):
    """
    Train an Ensemble of XGBoost and Random Forest using SMOTE
    """
    print("\n" + "="*70)
    print("ðŸ§  TRAINING ENSEMBLE MODEL (XGBOOST + RF)")
    print("="*70)
    
    # Split data (Stratified to maintain class ratio)
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    
    print(f"âš™ï¸  Applying SMOTE for class balancing...")
    
    # Define Classifiers
    rf_clf = RandomForestClassifier(
        n_estimators=200, 
        max_depth=15, 
        class_weight='balanced',
        random_state=42
    )
    
    xgb_clf = XGBClassifier(
        n_estimators=200,
        learning_rate=0.05,
        max_depth=6,
        eval_metric='logloss',
        use_label_encoder=False,
        random_state=42
    )
    
    # Ensemble (Voting)
    ensemble_clf = VotingClassifier(
        estimators=[
            ('rf', rf_clf),
            ('xgb', xgb_clf)
        ],
        voting='soft'  # Probability averaging
    )
    
    # Create Pipeline: Scale -> Balance -> Train
    pipeline = Pipeline([
        ('scaler', StandardScaler()),
        ('smote', SMOTE(random_state=42)),
        ('feature_selection', 'passthrough'), # Placeholder for potential RFE
        ('classifier', ensemble_clf)
    ])
    
    print("ðŸŒ² Training Ensemble Model...")
    pipeline.fit(X_train, y_train)
    
    # ========================================================================
    # STEP 3: EVALUATION
    # ========================================================================
    
    print("\nðŸ“Š MODEL EVALUATION:")
    
    # Predictions
    y_pred = pipeline.predict(X_test)
    y_prob = pipeline.predict_proba(X_test)[:, 1]
    
    # Metrics
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    roc_auc = roc_auc_score(y_test, y_prob)
    
    print(f"\n   ðŸŽ¯ TEST ACCURACY:   {accuracy*100:.2f}%")
    print(f"   ðŸ“ˆ Precision:       {precision:.4f}")
    print(f"   ðŸ“‰ Recall (Sens.):  {recall:.4f}")
    print(f"   âš–ï¸  F1 Score:        {f1:.4f}")
    print(f"   ðŸŒŸ ROC AUC:         {roc_auc:.4f}")
    
    # Cross-Validation Verification
    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
    cv_scores = cross_val_score(pipeline, X, y, cv=cv, scoring='accuracy')
    print(f"\n   ðŸ›¡ï¸  5-Fold CV Accuracy: {cv_scores.mean()*100:.2f}% (Â±{cv_scores.std()*100:.2f}%)")
    
    print(f"\nðŸ“Š Confusion Matrix:")
    print(confusion_matrix(y_test, y_pred))
    
    return pipeline, accuracy, f1

# ============================================================================
# MAIN
# ============================================================================

def main():
    X, y, _ = load_and_preprocess_data()
    
    if X is None:
        return

    # Train
    model_pipeline, acc, f1 = train_ensemble_model(X, y)
    
    # Save
    model_path = os.path.join(MODEL_DIR, 'model_ensemble.joblib')
    
    # Save entire pipeline (includes Scaler and Model)
    joblib.dump(model_pipeline, model_path)
    
    # Create symlink or copy to 'model.joblib' for app compatibility
    default_model_path = os.path.join(MODEL_DIR, 'model.joblib')
    joblib.dump(model_pipeline, default_model_path)
    
    print("\n" + "="*70)
    print("âœ… ACCURACY OPTIMIZATION COMPLETE")
    print("="*70)
    print(f"   Model saved to: {default_model_path}")
    print("   Pipeline includes: Scaling -> SMOTE -> XGBoost+RF Ensemble")
    print("\nðŸ‘‰ Restart the ML Service to apply changes!")

if __name__ == '__main__':
    main()
